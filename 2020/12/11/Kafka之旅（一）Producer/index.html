<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"jianghao1123.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.23.1","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="&emsp;&emsp;看Kafka源码主要是因为业务使用过程中的一个异常，异常部分堆栈如下： 12345678910111213141516171819202122org.apache.kafka.clients.consumer.CommitFailedException: Commit cannot be completed since the group has already rebal">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka之旅（一）Producer">
<meta property="og:url" content="https://jianghao1123.github.io/2020/12/11/Kafka%E4%B9%8B%E6%97%85%EF%BC%88%E4%B8%80%EF%BC%89Producer/index.html">
<meta property="og:site_name" content="矩阵编程">
<meta property="og:description" content="&emsp;&emsp;看Kafka源码主要是因为业务使用过程中的一个异常，异常部分堆栈如下： 12345678910111213141516171819202122org.apache.kafka.clients.consumer.CommitFailedException: Commit cannot be completed since the group has already rebal">
<meta property="og:locale">
<meta property="article:published_time" content="2020-12-11T02:43:51.000Z">
<meta property="article:modified_time" content="2020-12-11T02:43:51.556Z">
<meta property="article:author" content="functm">
<meta property="article:tag" content="Kafka">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://jianghao1123.github.io/2020/12/11/Kafka%E4%B9%8B%E6%97%85%EF%BC%88%E4%B8%80%EF%BC%89Producer/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-Hans","comments":true,"permalink":"https://jianghao1123.github.io/2020/12/11/Kafka%E4%B9%8B%E6%97%85%EF%BC%88%E4%B8%80%EF%BC%89Producer/","path":"2020/12/11/Kafka之旅（一）Producer/","title":"Kafka之旅（一）Producer"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Kafka之旅（一）Producer | 矩阵编程</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  






  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">矩阵编程</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#KafkaProducer"><span class="nav-number">1.</span> <span class="nav-text">KafkaProducer</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#send"><span class="nav-number">1.0.1.</span> <span class="nav-text">send</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RecordAccumulator"><span class="nav-number">2.</span> <span class="nav-text">RecordAccumulator</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#append"><span class="nav-number">2.0.1.</span> <span class="nav-text">append</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Sender"><span class="nav-number">3.</span> <span class="nav-text">Sender</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#run"><span class="nav-number">3.0.1.</span> <span class="nav-text">run</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#KafkaClient"><span class="nav-number">4.</span> <span class="nav-text">KafkaClient</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#send-1"><span class="nav-number">4.0.1.</span> <span class="nav-text">send</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#poll"><span class="nav-number">4.0.2.</span> <span class="nav-text">poll</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">5.</span> <span class="nav-text">总结</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">functm</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">54</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">20</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://jianghao1123.github.io/2020/12/11/Kafka%E4%B9%8B%E6%97%85%EF%BC%88%E4%B8%80%EF%BC%89Producer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="functm">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="矩阵编程">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Kafka之旅（一）Producer | 矩阵编程">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Kafka之旅（一）Producer
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-12-11 10:43:51" itemprop="dateCreated datePublished" datetime="2020-12-11T10:43:51+08:00">2020-12-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Kafka/" itemprop="url" rel="index"><span itemprop="name">Kafka</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>&emsp;&emsp;看Kafka源码主要是因为业务使用过程中的一个异常，异常部分堆栈如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">org.apache.kafka.clients.consumer.CommitFailedException: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to <span class="title function_">poll</span><span class="params">()</span> was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address <span class="built_in">this</span> either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in <span class="title function_">poll</span><span class="params">()</span> with max.poll.records.</span><br><span class="line">	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetCommitResponseHandler.handle(ConsumerCoordinator.java:<span class="number">900</span>)</span><br><span class="line">	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetCommitResponseHandler.handle(ConsumerCoordinator.java:<span class="number">840</span>)</span><br><span class="line">	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$CoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:<span class="number">978</span>)</span><br><span class="line">	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$CoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:<span class="number">958</span>)</span><br><span class="line">	at org.apache.kafka.clients.consumer.internals.RequestFuture$<span class="number">1.</span>onSuccess(RequestFuture.java:<span class="number">204</span>)</span><br><span class="line">	at org.apache.kafka.clients.consumer.internals.RequestFuture.fireSuccess(RequestFuture.java:<span class="number">167</span>)</span><br><span class="line">	at org.apache.kafka.clients.consumer.internals.RequestFuture.complete(RequestFuture.java:<span class="number">127</span>)</span><br><span class="line">	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler.fireCompletion(ConsumerNetworkClient.java:<span class="number">578</span>)</span><br><span class="line">	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.firePendingCompletedRequests(ConsumerNetworkClient.java:<span class="number">388</span>)</span><br><span class="line">	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:<span class="number">294</span>)</span><br><span class="line">	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:<span class="number">233</span>)</span><br><span class="line">	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:<span class="number">212</span>)</span><br><span class="line">	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:<span class="number">693</span>)</span><br><span class="line">	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:<span class="number">1454</span>)</span><br><span class="line">	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.commitIfNecessary(KafkaMessageListenerContainer.java:<span class="number">2039</span>)</span><br><span class="line">	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.processCommits(KafkaMessageListenerContainer.java:<span class="number">1862</span>)</span><br><span class="line">	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:<span class="number">983</span>)</span><br><span class="line">	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:<span class="number">929</span>)</span><br><span class="line">	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:<span class="number">511</span>)</span><br><span class="line">	at java.util.concurrent.FutureTask.run(FutureTask.java:<span class="number">266</span>)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:<span class="number">748</span>)</span><br></pre></td></tr></table></figure>
<p>本着技术源于业务但不止于业务，我决定带着这个问题去Kafka源码探究一番。当然本文的专题不是为了寻找或者解决这个问题，这个问题会在下一篇Consumer的笔记中分析，本文还是着重于Kafka Producer的剖析。</p>
<span id="more"></span>
<h3 id="KafkaProducer"><a href="#KafkaProducer" class="headerlink" title="KafkaProducer"></a>KafkaProducer</h3><h5 id="send"><a href="#send" class="headerlink" title="send"></a>send</h5><p>&emsp;&emsp;直接从KafkaProducer的**send(ProducerRecord&lt;K, V&gt; record, Callback callback)**开始：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Future&lt;RecordMetadata&gt; <span class="title function_">send</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> &#123;</span><br><span class="line">    <span class="comment">// intercept the record, which can be potentially modified; this method does not throw exceptions</span></span><br><span class="line">    ProducerRecord&lt;K, V&gt; interceptedRecord = <span class="built_in">this</span>.interceptors.onSend(record);</span><br><span class="line">    <span class="keyword">return</span> doSend(interceptedRecord, callback);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Implementation of asynchronously send a record to a topic.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> Future&lt;RecordMetadata&gt; <span class="title function_">doSend</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> &#123;</span><br><span class="line">    <span class="type">TopicPartition</span> <span class="variable">tp</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        throwIfProducerClosed();</span><br><span class="line">        <span class="comment">// first make sure the metadata for the topic is available</span></span><br><span class="line">        <span class="type">long</span> <span class="variable">nowMs</span> <span class="operator">=</span> time.milliseconds();</span><br><span class="line">        ClusterAndWaitTime clusterAndWaitTime;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), nowMs, maxBlockTimeMs);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (KafkaException e) &#123;</span><br><span class="line">            <span class="keyword">if</span> (metadata.isClosed())</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">KafkaException</span>(<span class="string">&quot;Producer closed while send in progress&quot;</span>, e);</span><br><span class="line">            <span class="keyword">throw</span> e;</span><br><span class="line">        &#125;</span><br><span class="line">        nowMs += clusterAndWaitTime.waitedOnMetadataMs;</span><br><span class="line">        <span class="type">long</span> <span class="variable">remainingWaitMs</span> <span class="operator">=</span> Math.max(<span class="number">0</span>, maxBlockTimeMs - clusterAndWaitTime.waitedOnMetadataMs);</span><br><span class="line">        <span class="type">Cluster</span> <span class="variable">cluster</span> <span class="operator">=</span> clusterAndWaitTime.cluster;</span><br><span class="line">        <span class="type">byte</span>[] serializedKey;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            serializedKey = keySerializer.serialize(record.topic(), record.headers(), record.key());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (ClassCastException cce) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">SerializationException</span>(<span class="string">&quot;Can&#x27;t convert key of class &quot;</span> + record.key().getClass().getName() +</span><br><span class="line">                    <span class="string">&quot; to class &quot;</span> + producerConfig.getClass(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).getName() +</span><br><span class="line">                    <span class="string">&quot; specified in key.serializer&quot;</span>, cce);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">byte</span>[] serializedValue;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            serializedValue = valueSerializer.serialize(record.topic(), record.headers(), record.value());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (ClassCastException cce) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">SerializationException</span>(<span class="string">&quot;Can&#x27;t convert value of class &quot;</span> + record.value().getClass().getName() +</span><br><span class="line">                    <span class="string">&quot; to class &quot;</span> + producerConfig.getClass(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG).getName() +</span><br><span class="line">                    <span class="string">&quot; specified in value.serializer&quot;</span>, cce);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">int</span> <span class="variable">partition</span> <span class="operator">=</span> partition(record, serializedKey, serializedValue, cluster);</span><br><span class="line">        tp = <span class="keyword">new</span> <span class="title class_">TopicPartition</span>(record.topic(), partition);</span><br><span class="line"></span><br><span class="line">        setReadOnly(record.headers());</span><br><span class="line">        Header[] headers = record.headers().toArray();</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> <span class="variable">serializedSize</span> <span class="operator">=</span> AbstractRecords.estimateSizeInBytesUpperBound(apiVersions.maxUsableProduceMagic(),</span><br><span class="line">                compressionType, serializedKey, serializedValue, headers);</span><br><span class="line">        ensureValidRecordSize(serializedSize);</span><br><span class="line">        <span class="type">long</span> <span class="variable">timestamp</span> <span class="operator">=</span> record.timestamp() == <span class="literal">null</span> ? nowMs : record.timestamp();</span><br><span class="line">        <span class="keyword">if</span> (log.isTraceEnabled()) &#123;</span><br><span class="line">            log.trace(<span class="string">&quot;Attempting to append record &#123;&#125; with callback &#123;&#125; to topic &#123;&#125; partition &#123;&#125;&quot;</span>, record, callback, record.topic(), partition);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// producer callback will make sure to call both &#x27;callback&#x27; and interceptor callback</span></span><br><span class="line">        <span class="type">Callback</span> <span class="variable">interceptCallback</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">InterceptorCallback</span>&lt;&gt;(callback, <span class="built_in">this</span>.interceptors, tp);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (transactionManager != <span class="literal">null</span> &amp;&amp; transactionManager.isTransactional()) &#123;</span><br><span class="line">            transactionManager.failIfNotReadyForSend();</span><br><span class="line">        &#125;</span><br><span class="line">        RecordAccumulator.<span class="type">RecordAppendResult</span> <span class="variable">result</span> <span class="operator">=</span> accumulator.append(tp, timestamp, serializedKey,</span><br><span class="line">                serializedValue, headers, interceptCallback, remainingWaitMs, <span class="literal">true</span>, nowMs);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (result.abortForNewBatch) &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">prevPartition</span> <span class="operator">=</span> partition;</span><br><span class="line">            partitioner.onNewBatch(record.topic(), cluster, prevPartition);</span><br><span class="line">            partition = partition(record, serializedKey, serializedValue, cluster);</span><br><span class="line">            tp = <span class="keyword">new</span> <span class="title class_">TopicPartition</span>(record.topic(), partition);</span><br><span class="line">            <span class="keyword">if</span> (log.isTraceEnabled()) &#123;</span><br><span class="line">                log.trace(<span class="string">&quot;Retrying append due to new batch creation for topic &#123;&#125; partition &#123;&#125;. The old partition was &#123;&#125;&quot;</span>, record.topic(), partition, prevPartition);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// producer callback will make sure to call both &#x27;callback&#x27; and interceptor callback</span></span><br><span class="line">            interceptCallback = <span class="keyword">new</span> <span class="title class_">InterceptorCallback</span>&lt;&gt;(callback, <span class="built_in">this</span>.interceptors, tp);</span><br><span class="line"></span><br><span class="line">            result = accumulator.append(tp, timestamp, serializedKey,</span><br><span class="line">                serializedValue, headers, interceptCallback, remainingWaitMs, <span class="literal">false</span>, nowMs);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (transactionManager != <span class="literal">null</span> &amp;&amp; transactionManager.isTransactional())</span><br><span class="line">            transactionManager.maybeAddPartitionToTransaction(tp);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (result.batchIsFull || result.newBatchCreated) &#123;</span><br><span class="line">            log.trace(<span class="string">&quot;Waking up the sender since topic &#123;&#125; partition &#123;&#125; is either full or getting a new batch&quot;</span>, record.topic(), partition);</span><br><span class="line">            <span class="built_in">this</span>.sender.wakeup();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result.future;</span><br><span class="line">        <span class="comment">// handling exceptions and record the errors;</span></span><br><span class="line">        <span class="comment">// for API exceptions return them in the future,</span></span><br><span class="line">        <span class="comment">// for other exceptions throw directly</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> (ApiException e) &#123;</span><br><span class="line">        log.debug(<span class="string">&quot;Exception occurred during message send:&quot;</span>, e);</span><br><span class="line">        <span class="keyword">if</span> (callback != <span class="literal">null</span>)</span><br><span class="line">            callback.onCompletion(<span class="literal">null</span>, e);</span><br><span class="line">        <span class="built_in">this</span>.errors.record();</span><br><span class="line">        <span class="built_in">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">FutureFailure</span>(e);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">        <span class="built_in">this</span>.errors.record();</span><br><span class="line">        <span class="built_in">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">InterruptException</span>(e);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (KafkaException e) &#123;</span><br><span class="line">        <span class="built_in">this</span>.errors.record();</span><br><span class="line">        <span class="built_in">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="comment">// we notify interceptor about all exceptions, since onSend is called before anything else in this method</span></span><br><span class="line">        <span class="built_in">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol>
<li>从send方法很简单，主要调用doSend，不过从这里可以大致看出来kafka的发送其实是异步的，下面主要是分析doSend步骤</li>
<li><strong>waitOnMetadata</strong>通过<strong>ProducerMetadata</strong>获取topic metadata信息，这里分两种情况：如果topic元数据已经存在会立即返回，否则需要等待broker响应（先不细讲）</li>
<li>使用用户设定的<strong>keySerializer</strong>和<strong>valueSerializer</strong>进行编码，根据<strong>Partitioner</strong>进行分区</li>
<li>往<strong>RecordAccumulator</strong>追加消息，如果在append的时候发现该batch已经出队，需要创建一个新的batch，会退出append方法并再次回调<strong>Partitioner</strong>进行分区，然后重新append（abortOnNewBatch参数标识）。</li>
<li>忽略一些<strong>TransactionManager</strong>的代码，最后可以看到如果该batch已经满了，或者是新的batch，调用**Sender#wakeup()<strong>，其实这个wakeup实际是调用</strong>java.nio.channels.Selector#wakeup()**。</li>
</ol>
<blockquote>
<p><strong>java.nio.channels.Selector#wakeup()</strong> 该方法会让处在阻塞状态的select()方法立刻返回（selector上的第一个未返回的选择操作），如果当前没有线程阻塞在select上，那么下一次对select方法的一次调用将立即返回。</p>
</blockquote>
<h3 id="RecordAccumulator"><a href="#RecordAccumulator" class="headerlink" title="RecordAccumulator"></a>RecordAccumulator</h3><h5 id="append"><a href="#append" class="headerlink" title="append"></a>append</h5><p>&emsp;&emsp;接下来看<strong>RecordAccumulator</strong>的代码，<strong>RecordAccumulator</strong>其实是一个基于内存的消息队列管理器，其内部维护了一个ConcurrentMap&lt;TopicPartition, Deque<ProducerBatch>&gt;，即一个topic分区对应一个发送批次队列。我们看append方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> RecordAppendResult <span class="title function_">append</span><span class="params">(TopicPartition tp,</span></span><br><span class="line"><span class="params">                                 <span class="type">long</span> timestamp,</span></span><br><span class="line"><span class="params">                                 <span class="type">byte</span>[] key,</span></span><br><span class="line"><span class="params">                                 <span class="type">byte</span>[] value,</span></span><br><span class="line"><span class="params">                                 Header[] headers,</span></span><br><span class="line"><span class="params">                                 Callback callback,</span></span><br><span class="line"><span class="params">                                 <span class="type">long</span> maxTimeToBlock,</span></span><br><span class="line"><span class="params">                                 <span class="type">boolean</span> abortOnNewBatch,</span></span><br><span class="line"><span class="params">                                 <span class="type">long</span> nowMs)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">    <span class="comment">// We keep track of the number of appending thread to make sure we do not miss batches in</span></span><br><span class="line">    <span class="comment">// abortIncompleteBatches().</span></span><br><span class="line">    appendsInProgress.incrementAndGet();</span><br><span class="line">    <span class="type">ByteBuffer</span> <span class="variable">buffer</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">if</span> (headers == <span class="literal">null</span>) headers = Record.EMPTY_HEADERS;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// check if we have an in-progress batch</span></span><br><span class="line">        Deque&lt;ProducerBatch&gt; dq = getOrCreateDeque(tp);</span><br><span class="line">        <span class="keyword">synchronized</span> (dq) &#123;</span><br><span class="line">            <span class="keyword">if</span> (closed)</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">KafkaException</span>(<span class="string">&quot;Producer closed while send in progress&quot;</span>);</span><br><span class="line">            <span class="type">RecordAppendResult</span> <span class="variable">appendResult</span> <span class="operator">=</span> tryAppend(timestamp, key, value, headers, callback, dq, nowMs);</span><br><span class="line">            <span class="keyword">if</span> (appendResult != <span class="literal">null</span>)</span><br><span class="line">                <span class="keyword">return</span> appendResult;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// we don&#x27;t have an in-progress record batch try to allocate a new batch</span></span><br><span class="line">        <span class="keyword">if</span> (abortOnNewBatch) &#123;</span><br><span class="line">            <span class="comment">// Return a result that will cause another call to append.</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">RecordAppendResult</span>(<span class="literal">null</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">byte</span> <span class="variable">maxUsableMagic</span> <span class="operator">=</span> apiVersions.maxUsableProduceMagic();</span><br><span class="line">        <span class="type">int</span> <span class="variable">size</span> <span class="operator">=</span> Math.max(<span class="built_in">this</span>.batchSize, AbstractRecords.estimateSizeInBytesUpperBound(maxUsableMagic, compression, key, value, headers));</span><br><span class="line">        log.trace(<span class="string">&quot;Allocating a new &#123;&#125; byte message buffer for topic &#123;&#125; partition &#123;&#125;&quot;</span>, size, tp.topic(), tp.partition());</span><br><span class="line">        buffer = free.allocate(size, maxTimeToBlock);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Update the current time in case the buffer allocation blocked above.</span></span><br><span class="line">        nowMs = time.milliseconds();</span><br><span class="line">        <span class="keyword">synchronized</span> (dq) &#123;</span><br><span class="line">            <span class="comment">// Need to check if producer is closed again after grabbing the dequeue lock.</span></span><br><span class="line">            <span class="keyword">if</span> (closed)</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">KafkaException</span>(<span class="string">&quot;Producer closed while send in progress&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="type">RecordAppendResult</span> <span class="variable">appendResult</span> <span class="operator">=</span> tryAppend(timestamp, key, value, headers, callback, dq, nowMs);</span><br><span class="line">            <span class="keyword">if</span> (appendResult != <span class="literal">null</span>) &#123;</span><br><span class="line">                <span class="comment">// Somebody else found us a batch, return the one we waited for! Hopefully this doesn&#x27;t happen often...</span></span><br><span class="line">                <span class="keyword">return</span> appendResult;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="type">MemoryRecordsBuilder</span> <span class="variable">recordsBuilder</span> <span class="operator">=</span> recordsBuilder(buffer, maxUsableMagic);</span><br><span class="line">            <span class="type">ProducerBatch</span> <span class="variable">batch</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ProducerBatch</span>(tp, recordsBuilder, nowMs);</span><br><span class="line">            <span class="type">FutureRecordMetadata</span> <span class="variable">future</span> <span class="operator">=</span> Objects.requireNonNull(batch.tryAppend(timestamp, key, value, headers,</span><br><span class="line">                    callback, nowMs));</span><br><span class="line"></span><br><span class="line">            dq.addLast(batch);</span><br><span class="line">            incomplete.add(batch);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// Don&#x27;t deallocate this buffer in the finally block as it&#x27;s being used in the record batch</span></span><br><span class="line">            buffer = <span class="literal">null</span>;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">RecordAppendResult</span>(future, dq.size() &gt; <span class="number">1</span> || batch.isFull(), <span class="literal">true</span>, <span class="literal">false</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (buffer != <span class="literal">null</span>)</span><br><span class="line">            free.deallocate(buffer);</span><br><span class="line">        appendsInProgress.decrementAndGet();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol>
<li>KafkaProducer是否线程安全可以在此处看出，每次append消息的操作会先锁住当前topic的分区，而每个分区之间追加消息互不干扰。</li>
<li><strong>tryAppend</strong>会尝试往当前队列的最后一个<strong>ProducerBatch</strong>追加消息（如果这个ProducerBatch存在且还有空间的话）</li>
<li>如果往队列中的<strong>ProducerBatch</strong>追加消息失败，会使用使用<strong>BufferPool#allocate(int size, long maxTimeToBlockMs)<strong>来申请一块空间用于创建新的</strong>ProducerBatch</strong>。Kafka在内存管理这一块和Netty类似，通过自主分配来绕过Java GC。</li>
<li><strong>ProducerBatch</strong>通过<strong>MemoryRecordsBuilder</strong>往申请到的ByteBuffer中写入消息。</li>
</ol>
<h3 id="Sender"><a href="#Sender" class="headerlink" title="Sender"></a>Sender</h3><h5 id="run"><a href="#run" class="headerlink" title="run"></a>run</h5><p>&emsp;&emsp;在<strong>KafkaProducer#send</strong>的最后可以看到如果该<strong>ProducerBatch</strong>已经满了，或者是新的batch，会调用<strong>Sender#wakeup()<strong>。这里Sender的作用其实不只是唤醒selector操作，首先Sender会运行在一个独立的线程中，它是一个</strong>Runnable</strong>，来看一下它的run逻辑：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">      log.debug(<span class="string">&quot;Starting Kafka producer I/O thread.&quot;</span>);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// main loop, runs until close is called</span></span><br><span class="line">      <span class="keyword">while</span> (running) &#123;</span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line">              runOnce();</span><br><span class="line">          &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">              log.error(<span class="string">&quot;Uncaught error in kafka producer I/O thread: &quot;</span>, e);</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      log.debug(<span class="string">&quot;Beginning shutdown of Kafka producer I/O thread, sending remaining records.&quot;</span>);</span><br><span class="line">  <span class="comment">// ...删除了后面一部分的代码...</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">runOnce</span><span class="params">()</span> &#123;</span><br><span class="line"><span class="comment">// ...删除了一些事务相关的代码...</span></span><br><span class="line">      <span class="type">long</span> <span class="variable">currentTimeMs</span> <span class="operator">=</span> time.milliseconds();</span><br><span class="line">      <span class="type">long</span> <span class="variable">pollTimeout</span> <span class="operator">=</span> sendProducerData(currentTimeMs);</span><br><span class="line">      client.poll(pollTimeout, currentTimeMs);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>从这里可以看到Kafka消息发送的一些痕迹，看一下sendProducerData处理：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="type">long</span> <span class="title function_">sendProducerData</span><span class="params">(<span class="type">long</span> now)</span> &#123;</span><br><span class="line">    <span class="type">Cluster</span> <span class="variable">cluster</span> <span class="operator">=</span> metadata.fetch();</span><br><span class="line">    <span class="comment">// get the list of partitions with data ready to send</span></span><br><span class="line">    RecordAccumulator.<span class="type">ReadyCheckResult</span> <span class="variable">result</span> <span class="operator">=</span> <span class="built_in">this</span>.accumulator.ready(cluster, now);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// if there are any partitions whose leaders are not known yet, force metadata update</span></span><br><span class="line">    <span class="keyword">if</span> (!result.unknownLeaderTopics.isEmpty()) &#123;</span><br><span class="line">        <span class="comment">// The set of topics with unknown leader contains topics with leader election pending as well as</span></span><br><span class="line">        <span class="comment">// topics which may have expired. Add the topic again to metadata to ensure it is included</span></span><br><span class="line">        <span class="comment">// and request metadata update, since there are messages to send to the topic.</span></span><br><span class="line">        <span class="keyword">for</span> (String topic : result.unknownLeaderTopics)</span><br><span class="line">            <span class="built_in">this</span>.metadata.add(topic, now);</span><br><span class="line"></span><br><span class="line">        log.debug(<span class="string">&quot;Requesting metadata update due to unknown leader topics from the batched records: &#123;&#125;&quot;</span>,</span><br><span class="line">            result.unknownLeaderTopics);</span><br><span class="line">        <span class="built_in">this</span>.metadata.requestUpdate();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// remove any nodes we aren&#x27;t ready to send to</span></span><br><span class="line">    Iterator&lt;Node&gt; iter = result.readyNodes.iterator();</span><br><span class="line">    <span class="type">long</span> <span class="variable">notReadyTimeout</span> <span class="operator">=</span> Long.MAX_VALUE;</span><br><span class="line">    <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">        <span class="type">Node</span> <span class="variable">node</span> <span class="operator">=</span> iter.next();</span><br><span class="line">        <span class="keyword">if</span> (!<span class="built_in">this</span>.client.ready(node, now)) &#123;</span><br><span class="line">            iter.remove();</span><br><span class="line">            notReadyTimeout = Math.min(notReadyTimeout, <span class="built_in">this</span>.client.pollDelayMs(node, now));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// create produce requests</span></span><br><span class="line">    Map&lt;Integer, List&lt;ProducerBatch&gt;&gt; batches = <span class="built_in">this</span>.accumulator.drain(cluster, result.readyNodes, <span class="built_in">this</span>.maxRequestSize, now);</span><br><span class="line">    addToInflightBatches(batches);</span><br><span class="line">    <span class="keyword">if</span> (guaranteeMessageOrder) &#123;</span><br><span class="line">        <span class="comment">// Mute all the partitions drained</span></span><br><span class="line">        <span class="keyword">for</span> (List&lt;ProducerBatch&gt; batchList : batches.values()) &#123;</span><br><span class="line">            <span class="keyword">for</span> (ProducerBatch batch : batchList)</span><br><span class="line">                <span class="built_in">this</span>.accumulator.mutePartition(batch.topicPartition);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    accumulator.resetNextBatchExpiryTime();</span><br><span class="line">    List&lt;ProducerBatch&gt; expiredInflightBatches = getExpiredInflightBatches(now);</span><br><span class="line">    List&lt;ProducerBatch&gt; expiredBatches = <span class="built_in">this</span>.accumulator.expiredBatches(now);</span><br><span class="line">    expiredBatches.addAll(expiredInflightBatches);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Reset the producer id if an expired batch has previously been sent to the broker. Also update the metrics</span></span><br><span class="line">    <span class="comment">// for expired batches. see the documentation of @TransactionState.resetIdempotentProducerId to understand why</span></span><br><span class="line">    <span class="comment">// we need to reset the producer id here.</span></span><br><span class="line">    <span class="keyword">if</span> (!expiredBatches.isEmpty())</span><br><span class="line">        log.trace(<span class="string">&quot;Expired &#123;&#125; batches in accumulator&quot;</span>, expiredBatches.size());</span><br><span class="line">    <span class="keyword">for</span> (ProducerBatch expiredBatch : expiredBatches) &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">errorMessage</span> <span class="operator">=</span> <span class="string">&quot;Expiring &quot;</span> + expiredBatch.recordCount + <span class="string">&quot; record(s) for &quot;</span> + expiredBatch.topicPartition</span><br><span class="line">            + <span class="string">&quot;:&quot;</span> + (now - expiredBatch.createdMs) + <span class="string">&quot; ms has passed since batch creation&quot;</span>;</span><br><span class="line">        failBatch(expiredBatch, -<span class="number">1</span>, NO_TIMESTAMP, <span class="keyword">new</span> <span class="title class_">TimeoutException</span>(errorMessage), <span class="literal">false</span>);</span><br><span class="line">        <span class="keyword">if</span> (transactionManager != <span class="literal">null</span> &amp;&amp; expiredBatch.inRetry()) &#123;</span><br><span class="line">            <span class="comment">// This ensures that no new batches are drained until the current in flight batches are fully resolved.</span></span><br><span class="line">            transactionManager.markSequenceUnresolved(expiredBatch);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    sensors.updateProduceRequestMetrics(batches);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// If we have any nodes that are ready to send + have sendable data, poll with 0 timeout so this can immediately</span></span><br><span class="line">    <span class="comment">// loop and try sending more data. Otherwise, the timeout will be the smaller value between next batch expiry</span></span><br><span class="line">    <span class="comment">// time, and the delay time for checking data availability. Note that the nodes may have data that isn&#x27;t yet</span></span><br><span class="line">    <span class="comment">// sendable due to lingering, backing off, etc. This specifically does not include nodes with sendable data</span></span><br><span class="line">    <span class="comment">// that aren&#x27;t ready to send since they would cause busy looping.</span></span><br><span class="line">    <span class="type">long</span> <span class="variable">pollTimeout</span> <span class="operator">=</span> Math.min(result.nextReadyCheckDelayMs, notReadyTimeout);</span><br><span class="line">    pollTimeout = Math.min(pollTimeout, <span class="built_in">this</span>.accumulator.nextExpiryTimeMs() - now);</span><br><span class="line">    pollTimeout = Math.max(pollTimeout, <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">if</span> (!result.readyNodes.isEmpty()) &#123;</span><br><span class="line">        log.trace(<span class="string">&quot;Nodes with data ready to send: &#123;&#125;&quot;</span>, result.readyNodes);</span><br><span class="line">        <span class="comment">// if some partitions are already ready to be sent, the select time would be 0;</span></span><br><span class="line">        <span class="comment">// otherwise if some partition already has some data accumulated but not ready yet,</span></span><br><span class="line">        <span class="comment">// the select time will be the time difference between now and its linger expiry time;</span></span><br><span class="line">        <span class="comment">// otherwise the select time will be the time difference between now and the metadata expiry time;</span></span><br><span class="line">        pollTimeout = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    sendProduceRequests(batches, now);</span><br><span class="line">    <span class="keyword">return</span> pollTimeout;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ol>
<li><strong>RecordAccumulator#ready</strong> 返回一些ProducerBatch的可用发送节点（Node）用于发送消息，以及一些无leader分区的topic以便再次请求其元数据。这里获取可用节点的逻辑是通过RecordAccumulator每个队列的ProducerBatch去验证，比如batch满了、达到linger.ms上限等。</li>
<li><strong>RecordAccumulator#drain</strong> 从筛选过的Node中获取相应的ProducerBatch（按照node分组），放入对应的inFlightBatches字典中，inFlightBatches是一个HashMap（Map&lt;TopicPartition, List<ProducerBatch>&gt;），用于存放发送中的消息批次。</li>
<li><strong>guaranteeMessageOrder</strong>这个参数源于<strong>max.in.flight.requests.per.connection</strong>，connection&#x3D;1的时候<strong>guaranteeMessageOrder&#x3D;true</strong>，这时候发送中的Topic分区信息放入<strong>RecordAccumulator.muted</strong>的列表中，标识这些topic分区的消息在发送中，在步骤2中将不会返回muted列表中对应topic分区的ProducerBatch（步骤1同理也不会返回对应topic分区的node）。以上可以看出<strong>guaranteeMessageOrder</strong>保证了同一个分区消息的有序性。</li>
<li>从inFlightBatches和RecordAccumulator的batch队列中移除一些超时的消息批次，过期时间由<strong>delivery.timeout.ms</strong>指定。这是Kafka 2.4中新增的参数，用于控制消息错误重试。</li>
<li>最后调用<strong>sendProduceRequests</strong>发送消息</li>
</ol>
<blockquote>
<p><strong>max.in.flight.requests.per.connection</strong> 指定生产者在收到Broker响应之前可以发送多少请求，如果设置为1可以保证同分区消息的有序性，否则可能因为retries&gt;1导致乱序。</p>
</blockquote>
<p>继续看<strong>Sender#sendProduceRequests</strong>方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">sendProduceRequests</span><span class="params">(Map&lt;Integer, List&lt;ProducerBatch&gt;&gt; collated, <span class="type">long</span> now)</span> &#123;</span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;Integer, List&lt;ProducerBatch&gt;&gt; entry : collated.entrySet())</span><br><span class="line">        sendProduceRequest(now, entry.getKey(), acks, requestTimeoutMs, entry.getValue());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">sendProduceRequest</span><span class="params">(<span class="type">long</span> now, <span class="type">int</span> destination, <span class="type">short</span> acks, <span class="type">int</span> timeout, List&lt;ProducerBatch&gt; batches)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (batches.isEmpty())</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    Map&lt;TopicPartition, MemoryRecords&gt; produceRecordsByPartition = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;(batches.size());</span><br><span class="line">    <span class="keyword">final</span> Map&lt;TopicPartition, ProducerBatch&gt; recordsByPartition = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;(batches.size());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// find the minimum magic version used when creating the record sets</span></span><br><span class="line">    <span class="type">byte</span> <span class="variable">minUsedMagic</span> <span class="operator">=</span> apiVersions.maxUsableProduceMagic();</span><br><span class="line">    <span class="keyword">for</span> (ProducerBatch batch : batches) &#123;</span><br><span class="line">        <span class="keyword">if</span> (batch.magic() &lt; minUsedMagic)</span><br><span class="line">            minUsedMagic = batch.magic();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (ProducerBatch batch : batches) &#123;</span><br><span class="line">        <span class="type">TopicPartition</span> <span class="variable">tp</span> <span class="operator">=</span> batch.topicPartition;</span><br><span class="line">        <span class="type">MemoryRecords</span> <span class="variable">records</span> <span class="operator">=</span> batch.records();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// down convert if necessary to the minimum magic used. In general, there can be a delay between the time</span></span><br><span class="line">        <span class="comment">// that the producer starts building the batch and the time that we send the request, and we may have</span></span><br><span class="line">        <span class="comment">// chosen the message format based on out-dated metadata. In the worst case, we optimistically chose to use</span></span><br><span class="line">        <span class="comment">// the new message format, but found that the broker didn&#x27;t support it, so we need to down-convert on the</span></span><br><span class="line">        <span class="comment">// client before sending. This is intended to handle edge cases around cluster upgrades where brokers may</span></span><br><span class="line">        <span class="comment">// not all support the same message format version. For example, if a partition migrates from a broker</span></span><br><span class="line">        <span class="comment">// which is supporting the new magic version to one which doesn&#x27;t, then we will need to convert.</span></span><br><span class="line">        <span class="keyword">if</span> (!records.hasMatchingMagic(minUsedMagic))</span><br><span class="line">            records = batch.records().downConvert(minUsedMagic, <span class="number">0</span>, time).records();</span><br><span class="line">        produceRecordsByPartition.put(tp, records);</span><br><span class="line">        recordsByPartition.put(tp, batch);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">String</span> <span class="variable">transactionalId</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">if</span> (transactionManager != <span class="literal">null</span> &amp;&amp; transactionManager.isTransactional()) &#123;</span><br><span class="line">        transactionalId = transactionManager.transactionalId();</span><br><span class="line">    &#125;</span><br><span class="line">    ProduceRequest.<span class="type">Builder</span> <span class="variable">requestBuilder</span> <span class="operator">=</span> ProduceRequest.Builder.forMagic(minUsedMagic, acks, timeout,</span><br><span class="line">            produceRecordsByPartition, transactionalId);</span><br><span class="line">    <span class="type">RequestCompletionHandler</span> <span class="variable">callback</span> <span class="operator">=</span> response -&gt; handleProduceResponse(response, recordsByPartition, time.milliseconds());</span><br><span class="line"></span><br><span class="line">    <span class="type">String</span> <span class="variable">nodeId</span> <span class="operator">=</span> Integer.toString(destination);</span><br><span class="line">    <span class="type">ClientRequest</span> <span class="variable">clientRequest</span> <span class="operator">=</span> client.newClientRequest(nodeId, requestBuilder, now, acks != <span class="number">0</span>,</span><br><span class="line">            requestTimeoutMs, callback);</span><br><span class="line">    client.send(clientRequest, now);</span><br><span class="line">    log.trace(<span class="string">&quot;Sent produce request to &#123;&#125;: &#123;&#125;&quot;</span>, nodeId, requestBuilder);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>构造ClientRequest通过KafkaClient发送到各个node，并通过RequestCompletionHandler进行回调。这里发送完之后再回到<strong>Sender#runOnce</strong>中，可以看到马上调用了<strong>KafkaClient#poll</strong>。</p>
<h3 id="KafkaClient"><a href="#KafkaClient" class="headerlink" title="KafkaClient"></a>KafkaClient</h3><p>&emsp;&emsp;KafkaClient是一个接口，目前只有<strong>NetworkClient</strong>可用（另一个是mock测试），所以我们主要还是看<strong>NetworkClient</strong></p>
<h5 id="send-1"><a href="#send-1" class="headerlink" title="send"></a>send</h5><p><strong>NetworkClient#send</strong>主要调用doSend，doSend有多个方法重载，删繁就简这里只展示最底层的doSend：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">doSend</span><span class="params">(ClientRequest clientRequest, <span class="type">boolean</span> isInternalRequest, <span class="type">long</span> now, AbstractRequest request)</span> &#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">destination</span> <span class="operator">=</span> clientRequest.destination();</span><br><span class="line">    <span class="type">RequestHeader</span> <span class="variable">header</span> <span class="operator">=</span> clientRequest.makeHeader(request.version());</span><br><span class="line">    <span class="keyword">if</span> (log.isDebugEnabled()) &#123;</span><br><span class="line">        log.debug(<span class="string">&quot;Sending &#123;&#125; request with header &#123;&#125; and timeout &#123;&#125; to node &#123;&#125;: &#123;&#125;&quot;</span>,</span><br><span class="line">            clientRequest.apiKey(), header, clientRequest.requestTimeoutMs(), destination, request);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">Send</span> <span class="variable">send</span> <span class="operator">=</span> request.toSend(destination, header);</span><br><span class="line">    <span class="type">InFlightRequest</span> <span class="variable">inFlightRequest</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">InFlightRequest</span>(</span><br><span class="line">            clientRequest,</span><br><span class="line">            header,</span><br><span class="line">            isInternalRequest,</span><br><span class="line">            request,</span><br><span class="line">            send,</span><br><span class="line">            now);</span><br><span class="line">    <span class="built_in">this</span>.inFlightRequests.add(inFlightRequest);</span><br><span class="line">    selector.send(send);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>将<strong>ClientRequest</strong>转换为<strong>NetworkSend</strong>，并构造InFlightRequest加入InFlightRequests中作为进行中的请求，最后调用<strong>Selectable#send</strong>。Selectable也是一个接口，目前只有<strong>Selector</strong>可用（其余为测试），继续看<strong>Selector#send</strong>：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">send</span><span class="params">(Send send)</span> &#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">connectionId</span> <span class="operator">=</span> send.destination();</span><br><span class="line">    <span class="type">KafkaChannel</span> <span class="variable">channel</span> <span class="operator">=</span> openOrClosingChannelOrFail(connectionId);</span><br><span class="line">    <span class="keyword">if</span> (closingChannels.containsKey(connectionId)) &#123;</span><br><span class="line">        <span class="comment">// ensure notification via `disconnected`, leave channel in the state in which closing was triggered</span></span><br><span class="line">        <span class="built_in">this</span>.failedSends.add(connectionId);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            channel.setSend(send);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="comment">// update the state for consistency, the channel will be discarded after `close`</span></span><br><span class="line">            channel.state(ChannelState.FAILED_SEND);</span><br><span class="line">            <span class="comment">// ensure notification via `disconnected` when `failedSends` are processed in the next poll</span></span><br><span class="line">            <span class="built_in">this</span>.failedSends.add(connectionId);</span><br><span class="line">            close(channel, CloseMode.DISCARD_NO_NOTIFY);</span><br><span class="line">            <span class="keyword">if</span> (!(e <span class="keyword">instanceof</span> CancelledKeyException)) &#123;</span><br><span class="line">                log.error(<span class="string">&quot;Unexpected exception during send, closing connection &#123;&#125; and rethrowing exception &#123;&#125;&quot;</span>,</span><br><span class="line">                        connectionId, e);</span><br><span class="line">                <span class="keyword">throw</span> e;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>调用<strong>KafkaChannel#setSend</strong>，似乎不像个正经的发送方法，查看<strong>KafkaChannel#setSend</strong>代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setSend</span><span class="params">(Send send)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">this</span>.send != <span class="literal">null</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalStateException</span>(<span class="string">&quot;Attempt to begin a send operation with prior send operation still in progress, connection id is &quot;</span> + id);</span><br><span class="line">    <span class="built_in">this</span>.send = send;</span><br><span class="line">    <span class="built_in">this</span>.transportLayer.addInterestOps(SelectionKey.OP_WRITE);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>只是设置了<strong>NetworkSend</strong>，并向NIO中的<strong>SelectionKey</strong>注册一个写操作。send方法居然不是实际发送网络数据的地方，那么<strong>KafkaClient</strong>何时发数据？</p>
<h5 id="poll"><a href="#poll" class="headerlink" title="poll"></a>poll</h5><p>一下子没找到发网络请求的地方，既然没发数据那么poll的意义是什么？带着这个问题去看<strong>NetworkClient#poll</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> List&lt;ClientResponse&gt; <span class="title function_">poll</span><span class="params">(<span class="type">long</span> timeout, <span class="type">long</span> now)</span> &#123;</span><br><span class="line">        ensureActive();</span><br><span class="line">		<span class="comment">// ...这里删除了一些异常情况的代码...</span></span><br><span class="line">        <span class="type">long</span> <span class="variable">metadataTimeout</span> <span class="operator">=</span> metadataUpdater.maybeUpdate(now);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="built_in">this</span>.selector.poll(Utils.min(timeout, metadataTimeout, defaultRequestTimeoutMs));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            log.error(<span class="string">&quot;Unexpected error during I/O&quot;</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// process completed actions</span></span><br><span class="line">        <span class="type">long</span> <span class="variable">updatedNow</span> <span class="operator">=</span> <span class="built_in">this</span>.time.milliseconds();</span><br><span class="line">        List&lt;ClientResponse&gt; responses = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        handleCompletedSends(responses, updatedNow);</span><br><span class="line">        handleCompletedReceives(responses, updatedNow);</span><br><span class="line">        handleDisconnections(responses, updatedNow);</span><br><span class="line">        handleConnections();</span><br><span class="line">        handleInitiateApiVersionRequests(updatedNow);</span><br><span class="line">        handleTimedOutRequests(responses, updatedNow);</span><br><span class="line">        completeResponses(responses);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> responses;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>调用<strong>Selector#poll</strong>，如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">poll</span><span class="params">(<span class="type">long</span> timeout)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line"><span class="comment">// ...篇幅原因删除上面一部分代码...</span></span><br><span class="line">      <span class="type">int</span> <span class="variable">numReadyKeys</span> <span class="operator">=</span> select(timeout);</span><br><span class="line">      <span class="type">long</span> <span class="variable">endSelect</span> <span class="operator">=</span> time.nanoseconds();</span><br><span class="line">      <span class="built_in">this</span>.sensors.selectTime.record(endSelect - startSelect, time.milliseconds());</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (numReadyKeys &gt; <span class="number">0</span> || !immediatelyConnectedKeys.isEmpty() || dataInBuffers) &#123;</span><br><span class="line">          Set&lt;SelectionKey&gt; readyKeys = <span class="built_in">this</span>.nioSelector.selectedKeys();</span><br><span class="line"></span><br><span class="line">          <span class="comment">// Poll from channels that have buffered data (but nothing more from the underlying socket)</span></span><br><span class="line">          <span class="keyword">if</span> (dataInBuffers) &#123;</span><br><span class="line">              keysWithBufferedRead.removeAll(readyKeys); <span class="comment">//so no channel gets polled twice</span></span><br><span class="line">              Set&lt;SelectionKey&gt; toPoll = keysWithBufferedRead;</span><br><span class="line">              keysWithBufferedRead = <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;(); <span class="comment">//poll() calls will repopulate if needed</span></span><br><span class="line">              pollSelectionKeys(toPoll, <span class="literal">false</span>, endSelect);</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">          <span class="comment">// Poll from channels where the underlying socket has more data</span></span><br><span class="line">          pollSelectionKeys(readyKeys, <span class="literal">false</span>, endSelect);</span><br><span class="line">          <span class="comment">// Clear all selected keys so that they are included in the ready count for the next select</span></span><br><span class="line">          readyKeys.clear();</span><br><span class="line"></span><br><span class="line">          pollSelectionKeys(immediatelyConnectedKeys, <span class="literal">true</span>, endSelect);</span><br><span class="line">          immediatelyConnectedKeys.clear();</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          madeReadProgressLastPoll = <span class="literal">true</span>; <span class="comment">//no work is also &quot;progress&quot;</span></span><br><span class="line">      &#125;</span><br><span class="line"><span class="comment">// ...篇幅原因删除下面一部分代码...</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这里的select是调用<strong>java.nio.channels.Selector#select</strong>，通过遍历<strong>SelectionKey</strong>进行读写操作，这里删除了<strong>pollSelectionKeys</strong>大部分代码，只留下一个主干：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> <span class="title function_">pollSelectionKeys</span><span class="params">(Set&lt;SelectionKey&gt; selectionKeys,</span></span><br><span class="line"><span class="params">                       <span class="type">boolean</span> isImmediatelyConnected,</span></span><br><span class="line"><span class="params">                       <span class="type">long</span> currentTimeNanos)</span> &#123;</span><br><span class="line">    <span class="keyword">for</span> (SelectionKey key : determineHandlingOrder(selectionKeys)) &#123;</span><br><span class="line">        <span class="type">KafkaChannel</span> <span class="variable">channel</span> <span class="operator">=</span> channel(key);</span><br><span class="line">        <span class="comment">// ...删除一部分代码...</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// ...删除一部分代码...</span></span><br><span class="line">            <span class="keyword">if</span> (channel.ready() &amp;&amp; (key.isReadable() || channel.hasBytesBuffered()) &amp;&amp; !hasCompletedReceive(channel)</span><br><span class="line">                    &amp;&amp; !explicitlyMutedChannels.contains(channel)) &#123;</span><br><span class="line">                attemptRead(channel);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// ...删除一部分代码...</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                attemptWrite(key, channel, nowNanos);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                sendFailed = <span class="literal">true</span>;</span><br><span class="line">                <span class="keyword">throw</span> e;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// ...删除一部分代码...</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="comment">// ...删除一部分代码...</span></span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="comment">// ...删除一部分代码...</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol>
<li><strong>Selector#attemptRead</strong> 从<strong>KafkaChannel</strong>中读数据写入到<strong>NetworkReceive</strong>，当然实质上其实是从<strong>ScatteringByteChannel</strong>读数据写入到一个<strong>ByteBuffer</strong>中。</li>
<li><strong>Selector#attemptWrite</strong> 调用<strong>KafkaChannel#write</strong>：<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">long</span> <span class="title function_">write</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="keyword">if</span> (send == <span class="literal">null</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    midWrite = <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">return</span> send.writeTo(transportLayer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
这个send似曾相识，不就是上面的<strong>NetworkSend</strong>，这里writeTo其实是调用<strong>NetworkSend</strong>父类<strong>ByteBufferSend#writeTo</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">long</span> <span class="title function_">writeTo</span><span class="params">(GatheringByteChannel channel)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="type">long</span> <span class="variable">written</span> <span class="operator">=</span> channel.write(buffers);</span><br><span class="line">    <span class="keyword">if</span> (written &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">EOFException</span>(<span class="string">&quot;Wrote negative bytes to channel. This shouldn&#x27;t happen.&quot;</span>);</span><br><span class="line">    remaining -= written;</span><br><span class="line">    pending = TransportLayers.hasPendingWrites(channel);</span><br><span class="line">    <span class="keyword">return</span> written;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<blockquote>
<p>这里不论是<strong>GatheringByteChannel</strong>还是<strong>ScatteringByteChannel</strong>其实都是<strong>TransportLayer</strong>，<strong>TransportLayer</strong>实现了两者，不过它也是一个接口，实际的实现主要有：<strong>PlaintextTransportLayer</strong>和<strong>SslTransportLayer</strong>。</p>
</blockquote>
<p>发送网络数据的地方居然是在poll方法里面！不过<strong>NetworkClient#poll</strong>还未结束，回过头分析<strong>Selectable#poll</strong>，再继续看着下面做了什么（重新贴一遍这个代码回顾下）：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> List&lt;ClientResponse&gt; <span class="title function_">poll</span><span class="params">(<span class="type">long</span> timeout, <span class="type">long</span> now)</span> &#123;</span><br><span class="line">        ensureActive();</span><br><span class="line">		<span class="comment">// ...这里删除了一些异常情况的代码...</span></span><br><span class="line">        <span class="type">long</span> <span class="variable">metadataTimeout</span> <span class="operator">=</span> metadataUpdater.maybeUpdate(now);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="built_in">this</span>.selector.poll(Utils.min(timeout, metadataTimeout, defaultRequestTimeoutMs));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            log.error(<span class="string">&quot;Unexpected error during I/O&quot;</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// process completed actions</span></span><br><span class="line">        <span class="type">long</span> <span class="variable">updatedNow</span> <span class="operator">=</span> <span class="built_in">this</span>.time.milliseconds();</span><br><span class="line">        List&lt;ClientResponse&gt; responses = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        handleCompletedSends(responses, updatedNow);</span><br><span class="line">        handleCompletedReceives(responses, updatedNow);</span><br><span class="line">        handleDisconnections(responses, updatedNow);</span><br><span class="line">        handleConnections();</span><br><span class="line">        handleInitiateApiVersionRequests(updatedNow);</span><br><span class="line">        handleTimedOutRequests(responses, updatedNow);</span><br><span class="line">        completeResponses(responses);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> responses;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<ol>
<li><strong>handleCompletedSends</strong> 遍历已完成的数据发送请求，获取无需返回的请求在InFlightRequests队列中清除出去并加入到responses（List<ClientResponse>）列表中，代码如下<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">handleCompletedSends</span><span class="params">(List&lt;ClientResponse&gt; responses, <span class="type">long</span> now)</span> &#123;</span><br><span class="line">    <span class="comment">// if no response is expected then when the send is completed, return it</span></span><br><span class="line">    <span class="keyword">for</span> (Send send : <span class="built_in">this</span>.selector.completedSends()) &#123;</span><br><span class="line">        <span class="type">InFlightRequest</span> <span class="variable">request</span> <span class="operator">=</span> <span class="built_in">this</span>.inFlightRequests.lastSent(send.destination());</span><br><span class="line">        <span class="keyword">if</span> (!request.expectResponse) &#123;</span><br><span class="line">            <span class="built_in">this</span>.inFlightRequests.completeLastSent(send.destination());</span><br><span class="line">            responses.add(request.completed(<span class="literal">null</span>, now));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><strong>handleCompletedReceives</strong> 遍历poll中的响应数据NetworkReceive，在InFlightRequests队列中清除请求后根据不同的响应类型做处理。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">handleCompletedReceives</span><span class="params">(List&lt;ClientResponse&gt; responses, <span class="type">long</span> now)</span> &#123;</span><br><span class="line">    <span class="keyword">for</span> (NetworkReceive receive : <span class="built_in">this</span>.selector.completedReceives()) &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">source</span> <span class="operator">=</span> receive.source();</span><br><span class="line">        <span class="type">InFlightRequest</span> <span class="variable">req</span> <span class="operator">=</span> inFlightRequests.completeNext(source);</span><br><span class="line">        <span class="type">Struct</span> <span class="variable">responseStruct</span> <span class="operator">=</span> parseStructMaybeUpdateThrottleTimeMetrics(receive.payload(), req.header,</span><br><span class="line">            throttleTimeSensor, now);</span><br><span class="line">        <span class="type">AbstractResponse</span> <span class="variable">response</span> <span class="operator">=</span> AbstractResponse.</span><br><span class="line">            parseResponse(req.header.apiKey(), responseStruct, req.header.apiVersion());</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (log.isDebugEnabled()) &#123;</span><br><span class="line">            log.debug(<span class="string">&quot;Received &#123;&#125; response from node &#123;&#125; for request with header &#123;&#125;: &#123;&#125;&quot;</span>,</span><br><span class="line">                req.header.apiKey(), req.destination, req.header, response);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// If the received response includes a throttle delay, throttle the connection.</span></span><br><span class="line">        maybeThrottle(response, req.header.apiVersion(), req.destination, now);</span><br><span class="line">        <span class="keyword">if</span> (req.isInternalRequest &amp;&amp; response <span class="keyword">instanceof</span> MetadataResponse)</span><br><span class="line">            metadataUpdater.handleSuccessfulResponse(req.header, now, (MetadataResponse) response);</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (req.isInternalRequest &amp;&amp; response <span class="keyword">instanceof</span> ApiVersionsResponse)</span><br><span class="line">            handleApiVersionsResponse(responses, req, now, (ApiVersionsResponse) response);</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            responses.add(req.completed(response, now));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><strong>handleDisconnections</strong> 获取失活节点并更新节点状态为失活（ConnectionState.DISCONNECTED），并从InFlightRequests删除这些节点的请求。</li>
<li><strong>handleConnections</strong> 处理活跃节点，如果该节点时首次连接标识节点状态为ConnectionState.CHECKING_API_VERSIONS（需要获取节点的API版本信息），否则标识为ConnectionState.READY。</li>
<li><strong>handleInitiateApiVersionRequests</strong> 对于步骤4新加入的节点构造一些请求用于获取API版本，以便下一次poll能够获取。</li>
<li><strong>handleTimedOutRequests</strong> 遍历InFlightRequests中超时的请求，断开连接，后续处理和步骤3一样。</li>
<li><strong>completeResponses</strong> 回调<strong>RequestCompletionHandler#onComplete</strong>。在消息发送的请求中RequestCompletionHandler其实是在<strong>Sender#sendProduceRequest</strong>这一步传入，其回调处理如下：<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Handle a produce response</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">handleProduceResponse</span><span class="params">(ClientResponse response, Map&lt;TopicPartition, ProducerBatch&gt; batches, <span class="type">long</span> now)</span> &#123;</span><br><span class="line">    <span class="type">RequestHeader</span> <span class="variable">requestHeader</span> <span class="operator">=</span> response.requestHeader();</span><br><span class="line">    <span class="type">int</span> <span class="variable">correlationId</span> <span class="operator">=</span> requestHeader.correlationId();</span><br><span class="line">    <span class="keyword">if</span> (response.wasDisconnected()) &#123;</span><br><span class="line">        log.trace(<span class="string">&quot;Cancelled request with header &#123;&#125; due to node &#123;&#125; being disconnected&quot;</span>,</span><br><span class="line">            requestHeader, response.destination());</span><br><span class="line">        <span class="keyword">for</span> (ProducerBatch batch : batches.values())</span><br><span class="line">            completeBatch(batch, <span class="keyword">new</span> <span class="title class_">ProduceResponse</span>.PartitionResponse(Errors.NETWORK_EXCEPTION), correlationId, now);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (response.versionMismatch() != <span class="literal">null</span>) &#123;</span><br><span class="line">        log.warn(<span class="string">&quot;Cancelled request &#123;&#125; due to a version mismatch with node &#123;&#125;&quot;</span>,</span><br><span class="line">                response, response.destination(), response.versionMismatch());</span><br><span class="line">        <span class="keyword">for</span> (ProducerBatch batch : batches.values())</span><br><span class="line">            completeBatch(batch, <span class="keyword">new</span> <span class="title class_">ProduceResponse</span>.PartitionResponse(Errors.UNSUPPORTED_VERSION), correlationId, now);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        log.trace(<span class="string">&quot;Received produce response from node &#123;&#125; with correlation id &#123;&#125;&quot;</span>, response.destination(), correlationId);</span><br><span class="line">        <span class="comment">// if we have a response, parse it</span></span><br><span class="line">        <span class="keyword">if</span> (response.hasResponse()) &#123;</span><br><span class="line">            <span class="type">ProduceResponse</span> <span class="variable">produceResponse</span> <span class="operator">=</span> (ProduceResponse) response.responseBody();</span><br><span class="line">            <span class="keyword">for</span> (Map.Entry&lt;TopicPartition, ProduceResponse.PartitionResponse&gt; entry : produceResponse.responses().entrySet()) &#123;</span><br><span class="line">                <span class="type">TopicPartition</span> <span class="variable">tp</span> <span class="operator">=</span> entry.getKey();</span><br><span class="line">                ProduceResponse.<span class="type">PartitionResponse</span> <span class="variable">partResp</span> <span class="operator">=</span> entry.getValue();</span><br><span class="line">                <span class="type">ProducerBatch</span> <span class="variable">batch</span> <span class="operator">=</span> batches.get(tp);</span><br><span class="line">                completeBatch(batch, partResp, correlationId, now);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">this</span>.sensors.recordLatency(response.destination(), response.requestLatencyMs());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// this is the acks = 0 case, just complete all requests</span></span><br><span class="line">            <span class="keyword">for</span> (ProducerBatch batch : batches.values()) &#123;</span><br><span class="line">                completeBatch(batch, <span class="keyword">new</span> <span class="title class_">ProduceResponse</span>.PartitionResponse(Errors.NONE), correlationId, now);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
都是在调用<strong>Sender#completeBatch</strong>，根据不同的响应结果传入不同的<strong>ProduceResponse.PartitionResponse</strong>参数：<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">completeBatch</span><span class="params">(ProducerBatch batch, ProduceResponse.PartitionResponse response, <span class="type">long</span> correlationId,</span></span><br><span class="line"><span class="params">                           <span class="type">long</span> now)</span> &#123;</span><br><span class="line">    <span class="type">Errors</span> <span class="variable">error</span> <span class="operator">=</span> response.error;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (error == Errors.MESSAGE_TOO_LARGE &amp;&amp; batch.recordCount &gt; <span class="number">1</span> &amp;&amp; !batch.isDone() &amp;&amp;</span><br><span class="line">            (batch.magic() &gt;= RecordBatch.MAGIC_VALUE_V2 || batch.isCompressed())) &#123;</span><br><span class="line">        <span class="comment">// If the batch is too large, we split the batch and send the split batches again. We do not decrement</span></span><br><span class="line">        <span class="comment">// the retry attempts in this case.</span></span><br><span class="line">        log.warn(</span><br><span class="line">            <span class="string">&quot;Got error produce response in correlation id &#123;&#125; on topic-partition &#123;&#125;, splitting and retrying (&#123;&#125; attempts left). Error: &#123;&#125;&quot;</span>,</span><br><span class="line">            correlationId,</span><br><span class="line">            batch.topicPartition,</span><br><span class="line">            <span class="built_in">this</span>.retries - batch.attempts(),</span><br><span class="line">            error);</span><br><span class="line">        <span class="keyword">if</span> (transactionManager != <span class="literal">null</span>)</span><br><span class="line">            transactionManager.removeInFlightBatch(batch);</span><br><span class="line">        <span class="built_in">this</span>.accumulator.splitAndReenqueue(batch);</span><br><span class="line">        maybeRemoveAndDeallocateBatch(batch);</span><br><span class="line">        <span class="built_in">this</span>.sensors.recordBatchSplit();</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error != Errors.NONE) &#123;</span><br><span class="line">        <span class="keyword">if</span> (canRetry(batch, response, now)) &#123;</span><br><span class="line">            log.warn(</span><br><span class="line">                <span class="string">&quot;Got error produce response with correlation id &#123;&#125; on topic-partition &#123;&#125;, retrying (&#123;&#125; attempts left). Error: &#123;&#125;&quot;</span>,</span><br><span class="line">                correlationId,</span><br><span class="line">                batch.topicPartition,</span><br><span class="line">                <span class="built_in">this</span>.retries - batch.attempts() - <span class="number">1</span>,</span><br><span class="line">                error);</span><br><span class="line">            reenqueueBatch(batch, now);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.DUPLICATE_SEQUENCE_NUMBER) &#123;</span><br><span class="line">            <span class="comment">// If we have received a duplicate sequence error, it means that the sequence number has advanced beyond</span></span><br><span class="line">            <span class="comment">// the sequence of the current batch, and we haven&#x27;t retained batch metadata on the broker to return</span></span><br><span class="line">            <span class="comment">// the correct offset and timestamp.</span></span><br><span class="line">            <span class="comment">//</span></span><br><span class="line">            <span class="comment">// The only thing we can do is to return success to the user and not return a valid offset and timestamp.</span></span><br><span class="line">            completeBatch(batch, response);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">final</span> RuntimeException exception;</span><br><span class="line">            <span class="keyword">if</span> (error == Errors.TOPIC_AUTHORIZATION_FAILED)</span><br><span class="line">                exception = <span class="keyword">new</span> <span class="title class_">TopicAuthorizationException</span>(Collections.singleton(batch.topicPartition.topic()));</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.CLUSTER_AUTHORIZATION_FAILED)</span><br><span class="line">                exception = <span class="keyword">new</span> <span class="title class_">ClusterAuthorizationException</span>(<span class="string">&quot;The producer is not authorized to do idempotent sends&quot;</span>);</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                exception = error.exception();</span><br><span class="line">            <span class="comment">// tell the user the result of their request. We only adjust sequence numbers if the batch didn&#x27;t exhaust</span></span><br><span class="line">            <span class="comment">// its retries -- if it did, we don&#x27;t know whether the sequence number was accepted or not, and</span></span><br><span class="line">            <span class="comment">// thus it is not safe to reassign the sequence.</span></span><br><span class="line">            failBatch(batch, response, exception, batch.attempts() &lt; <span class="built_in">this</span>.retries);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (error.exception() <span class="keyword">instanceof</span> InvalidMetadataException) &#123;</span><br><span class="line">            <span class="keyword">if</span> (error.exception() <span class="keyword">instanceof</span> UnknownTopicOrPartitionException) &#123;</span><br><span class="line">                log.warn(<span class="string">&quot;Received unknown topic or partition error in produce request on partition &#123;&#125;. The &quot;</span> +</span><br><span class="line">                        <span class="string">&quot;topic-partition may not exist or the user may not have Describe access to it&quot;</span>,</span><br><span class="line">                    batch.topicPartition);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                log.warn(<span class="string">&quot;Received invalid metadata error in produce request on partition &#123;&#125; due to &#123;&#125;. Going &quot;</span> +</span><br><span class="line">                        <span class="string">&quot;to request metadata update now&quot;</span>, batch.topicPartition, error.exception().toString());</span><br><span class="line">            &#125;</span><br><span class="line">            metadata.requestUpdate();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        completeBatch(batch, response);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Unmute the completed partition.</span></span><br><span class="line">    <span class="keyword">if</span> (guaranteeMessageOrder)</span><br><span class="line">        <span class="built_in">this</span>.accumulator.unmutePartition(batch.topicPartition);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>做一些错误处理，比如针对MESSAGE_TOO_LARGE这种错误，直接删除inFlightBatches中的batch并回收ByteBuffer内存，不会做什么重试处理；对于能重试的情况，会重新将ProducerBatch入RecordAccumulator对应的队列等等……</li>
<li>做一些回调处理，比如在KafkaProducer#send(ProducerRecord&lt;K, V&gt; record, Callback callback)中的callback会在此时进行回调</li>
<li>guaranteeMessageOrder&#x3D;true（保证消息顺序）情况下，从之前的<strong>muted</strong>列表中移除当前批次的topic分区。</li>
</ol>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>&emsp;&emsp;主要是总结下本次源码中看到的<strong>Kafka Producer</strong>高性能的一些点：</p>
<ul>
<li>异步、批量发送消息数据</li>
<li>以Partition为细粒度的并发能力</li>
<li><strong>BufferPool</strong>自主管理内存</li>
<li>Java NIO网络传输</li>
</ul>
<p>最后贴一下本次代码分析用到的调试Demo的pom依赖：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-kafka<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>kafka client版本为：kafka_2.13:2.6.0 。</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Kafka/" rel="tag"># Kafka</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2020/12/05/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%EF%BC%88DDD%EF%BC%89%E7%AC%94%E8%AE%B0/" rel="prev" title="领域驱动设计（DDD）笔记">
                  <i class="fa fa-angle-left"></i> 领域驱动设计（DDD）笔记
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2020/12/22/%E4%BB%8Emybatis%E5%88%B0mybatis-spring-boot-starter/" rel="next" title="从mybatis到mybatis-spring-boot-starter">
                  从mybatis到mybatis-spring-boot-starter <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">functm</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
